//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31968024
// Cuda compilation tools, release 12.0, V12.0.76
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_52
.address_size 64

	// .globl	kernel
.global .align 4 .u32 FILTER_SIZE = 3;

.visible .entry kernel(
	.param .u32 kernel_param_0,
	.param .u32 kernel_param_1,
	.param .u32 kernel_param_2,
	.param .u64 kernel_param_3,
	.param .u64 kernel_param_4
)
{
	.reg .pred 	%p<56>;
	.reg .f32 	%f<136>;
	.reg .b32 	%r<134>;
	.reg .f64 	%fd<41>;
	.reg .b64 	%rd<56>;


	ld.param.u32 	%r42, [kernel_param_0];
	ld.param.u32 	%r43, [kernel_param_1];
	ld.param.u32 	%r44, [kernel_param_2];
	ld.param.u64 	%rd13, [kernel_param_3];
	ld.param.u64 	%rd14, [kernel_param_4];
	cvta.to.global.u64 	%rd1, %rd13;
	cvta.to.global.u64 	%rd2, %rd14;
	mov.u32 	%r45, %ntid.x;
	mov.u32 	%r46, %ctaid.x;
	mov.u32 	%r47, %tid.x;
	mad.lo.s32 	%r1, %r46, %r45, %r47;
	mov.u32 	%r48, %ntid.y;
	mov.u32 	%r49, %ctaid.y;
	mov.u32 	%r50, %tid.y;
	mad.lo.s32 	%r2, %r49, %r48, %r50;
	cvt.rn.f32.u32 	%f43, %r42;
	mov.f32 	%f44, 0f42700000;
	div.rn.f32 	%f45, %f44, %f43;
	cvt.rn.f32.u32 	%f46, %r43;
	div.rn.f32 	%f47, %f44, %f46;
	cvt.rn.f32.u32 	%f48, %r1;
	fma.rn.f32 	%f49, %f45, %f48, 0fC1F00000;
	cvt.rn.f32.u32 	%f50, %r2;
	fma.rn.f32 	%f51, %f47, %f50, 0fC1F00000;
	mul.f32 	%f52, %f51, %f51;
	fma.rn.f32 	%f1, %f49, %f49, %f52;
	setp.leu.f32 	%p10, %f1, 0f44364000;
	mov.f32 	%f117, 0f3F7FDF3B;
	@%p10 bra 	$L__BB0_2;

	sqrt.rn.f32 	%f53, %f1;
	add.f32 	%f54, %f53, 0fC1D80000;
	cvt.f64.f32 	%fd1, %f54;
	div.rn.f64 	%fd2, %fd1, 0dC008000060000000;
	add.f64 	%fd3, %fd2, 0d3FF0000000000000;
	mul.f64 	%fd4, %fd3, 0d3FEFFBE76C8B4396;
	cvt.rn.f32.f64 	%f55, %fd4;
	setp.lt.f32 	%p11, %f55, 0f00000000;
	selp.f32 	%f117, 0f00000000, %f55, %p11;

$L__BB0_2:
	add.s32 	%r3, %r1, -1;
	setp.ge.u32 	%p12, %r3, %r42;
	add.s32 	%r4, %r2, -1;
	or.b32  	%r51, %r4, %r3;
	setp.lt.s32 	%p13, %r51, 0;
	or.pred  	%p14, %p12, %p13;
	setp.ge.u32 	%p15, %r4, %r43;
	or.pred  	%p1, %p15, %p14;
	mul.lo.s32 	%r5, %r2, %r42;
	sub.s32 	%r6, %r5, %r42;
	add.s32 	%r52, %r6, %r3;
	mul.lo.s32 	%r7, %r52, %r44;
	add.s32 	%r8, %r44, -1;
	add.s32 	%r53, %r7, %r8;
	mul.wide.u32 	%rd15, %r53, 4;
	add.s64 	%rd3, %rd1, %rd15;
	mov.f32 	%f119, 0f00000000;
	@%p1 bra 	$L__BB0_4;

	ld.global.u32 	%r54, [%rd3];
	cvt.rn.f32.u32 	%f57, %r54;
	cvt.f64.f32 	%fd5, %f57;
	div.rn.f64 	%fd6, %fd5, 0d406FE00000000000;
	add.f64 	%fd7, %fd6, 0d0000000000000000;
	cvt.rn.f32.f64 	%f119, %fd7;

$L__BB0_4:
	or.b32  	%r55, %r2, %r3;
	setp.lt.s32 	%p16, %r55, 0;
	or.pred  	%p18, %p12, %p16;
	setp.ge.u32 	%p19, %r2, %r43;
	or.pred  	%p2, %p19, %p18;
	add.s32 	%r56, %r5, %r3;
	mul.lo.s32 	%r9, %r56, %r44;
	add.s32 	%r57, %r9, %r8;
	mul.wide.u32 	%rd16, %r57, 4;
	add.s64 	%rd4, %rd1, %rd16;
	@%p2 bra 	$L__BB0_6;

	ld.global.u32 	%r58, [%rd4];
	cvt.rn.f32.u32 	%f58, %r58;
	cvt.f64.f32 	%fd8, %f58;
	div.rn.f64 	%fd9, %fd8, 0d406FE00000000000;
	cvt.f64.f32 	%fd10, %f119;
	add.f64 	%fd11, %fd9, %fd10;
	cvt.rn.f32.f64 	%f119, %fd11;

$L__BB0_6:
	add.s32 	%r10, %r2, 1;
	or.b32  	%r59, %r10, %r3;
	setp.lt.s32 	%p20, %r59, 0;
	or.pred  	%p22, %p12, %p20;
	setp.ge.u32 	%p23, %r10, %r43;
	or.pred  	%p3, %p23, %p22;
	shl.b32 	%r60, %r42, 1;
	add.s32 	%r11, %r6, %r60;
	add.s32 	%r61, %r11, %r3;
	mul.lo.s32 	%r12, %r61, %r44;
	add.s32 	%r62, %r12, %r8;
	mul.wide.u32 	%rd17, %r62, 4;
	add.s64 	%rd5, %rd1, %rd17;
	@%p3 bra 	$L__BB0_8;

	ld.global.u32 	%r63, [%rd5];
	cvt.rn.f32.u32 	%f59, %r63;
	cvt.f64.f32 	%fd12, %f59;
	div.rn.f64 	%fd13, %fd12, 0d406FE00000000000;
	cvt.f64.f32 	%fd14, %f119;
	add.f64 	%fd15, %fd13, %fd14;
	cvt.rn.f32.f64 	%f119, %fd15;

$L__BB0_8:
	or.b32  	%r64, %r4, %r1;
	setp.lt.s32 	%p24, %r64, 0;
	setp.ge.u32 	%p25, %r1, %r42;
	or.pred  	%p26, %p25, %p24;
	or.pred  	%p4, %p15, %p26;
	add.s32 	%r65, %r6, %r1;
	mul.lo.s32 	%r13, %r65, %r44;
	add.s32 	%r66, %r13, %r8;
	mul.wide.u32 	%rd18, %r66, 4;
	add.s64 	%rd6, %rd1, %rd18;
	@%p4 bra 	$L__BB0_10;

	ld.global.u32 	%r67, [%rd6];
	cvt.rn.f32.u32 	%f60, %r67;
	cvt.f64.f32 	%fd16, %f60;
	div.rn.f64 	%fd17, %fd16, 0d406FE00000000000;
	cvt.f64.f32 	%fd18, %f119;
	add.f64 	%fd19, %fd17, %fd18;
	cvt.rn.f32.f64 	%f119, %fd19;

$L__BB0_10:
	or.b32  	%r68, %r2, %r1;
	setp.lt.s32 	%p28, %r68, 0;
	or.pred  	%p30, %p25, %p28;
	or.pred  	%p5, %p19, %p30;
	add.s32 	%r69, %r5, %r1;
	mul.lo.s32 	%r14, %r69, %r44;
	add.s32 	%r70, %r14, %r8;
	cvt.u64.u32 	%rd7, %r70;
	mul.wide.u32 	%rd19, %r70, 4;
	add.s64 	%rd8, %rd1, %rd19;
	@%p5 bra 	$L__BB0_12;

	ld.global.u32 	%r71, [%rd8];
	cvt.rn.f32.u32 	%f61, %r71;
	cvt.f64.f32 	%fd20, %f61;
	div.rn.f64 	%fd21, %fd20, 0d406FE00000000000;
	cvt.f64.f32 	%fd22, %f119;
	add.f64 	%fd23, %fd21, %fd22;
	cvt.rn.f32.f64 	%f119, %fd23;

$L__BB0_12:
	or.b32  	%r72, %r10, %r1;
	setp.lt.s32 	%p32, %r72, 0;
	or.pred  	%p34, %p25, %p32;
	or.pred  	%p6, %p23, %p34;
	add.s32 	%r73, %r11, %r1;
	mul.lo.s32 	%r129, %r73, %r44;
	add.s32 	%r74, %r129, %r8;
	mul.wide.u32 	%rd20, %r74, 4;
	add.s64 	%rd9, %rd1, %rd20;
	@%p6 bra 	$L__BB0_14;

	ld.global.u32 	%r75, [%rd9];
	cvt.rn.f32.u32 	%f62, %r75;
	cvt.f64.f32 	%fd24, %f62;
	div.rn.f64 	%fd25, %fd24, 0d406FE00000000000;
	cvt.f64.f32 	%fd26, %f119;
	add.f64 	%fd27, %fd25, %fd26;
	cvt.rn.f32.f64 	%f119, %fd27;

$L__BB0_14:
	add.s32 	%r16, %r1, 1;
	setp.ge.u32 	%p36, %r16, %r42;
	or.b32  	%r76, %r4, %r16;
	setp.lt.s32 	%p37, %r76, 0;
	or.pred  	%p38, %p36, %p37;
	or.pred  	%p7, %p15, %p38;
	add.s32 	%r77, %r6, %r16;
	mul.lo.s32 	%r130, %r77, %r44;
	add.s32 	%r78, %r130, %r8;
	mul.wide.u32 	%rd21, %r78, 4;
	add.s64 	%rd10, %rd1, %rd21;
	@%p7 bra 	$L__BB0_16;

	ld.global.u32 	%r79, [%rd10];
	cvt.rn.f32.u32 	%f63, %r79;
	cvt.f64.f32 	%fd28, %f63;
	div.rn.f64 	%fd29, %fd28, 0d406FE00000000000;
	cvt.f64.f32 	%fd30, %f119;
	add.f64 	%fd31, %fd29, %fd30;
	cvt.rn.f32.f64 	%f119, %fd31;

$L__BB0_16:
	or.b32  	%r80, %r2, %r16;
	setp.lt.s32 	%p40, %r80, 0;
	or.pred  	%p42, %p36, %p40;
	or.pred  	%p8, %p19, %p42;
	add.s32 	%r81, %r5, %r16;
	mul.lo.s32 	%r131, %r81, %r44;
	add.s32 	%r82, %r131, %r8;
	mul.wide.u32 	%rd22, %r82, 4;
	add.s64 	%rd11, %rd1, %rd22;
	@%p8 bra 	$L__BB0_18;

	ld.global.u32 	%r83, [%rd11];
	cvt.rn.f32.u32 	%f64, %r83;
	cvt.f64.f32 	%fd32, %f64;
	div.rn.f64 	%fd33, %fd32, 0d406FE00000000000;
	cvt.f64.f32 	%fd34, %f119;
	add.f64 	%fd35, %fd33, %fd34;
	cvt.rn.f32.f64 	%f119, %fd35;

$L__BB0_18:
	or.b32  	%r84, %r10, %r16;
	setp.lt.s32 	%p44, %r84, 0;
	or.pred  	%p46, %p36, %p44;
	or.pred  	%p9, %p23, %p46;
	add.s32 	%r85, %r11, %r16;
	mul.lo.s32 	%r132, %r85, %r44;
	add.s32 	%r86, %r132, %r8;
	mul.wide.u32 	%rd23, %r86, 4;
	add.s64 	%rd12, %rd1, %rd23;
	@%p9 bra 	$L__BB0_20;

	ld.global.u32 	%r87, [%rd12];
	cvt.rn.f32.u32 	%f65, %r87;
	cvt.f64.f32 	%fd36, %f65;
	div.rn.f64 	%fd37, %fd36, 0d406FE00000000000;
	cvt.f64.f32 	%fd38, %f119;
	add.f64 	%fd39, %fd37, %fd38;
	cvt.rn.f32.f64 	%f119, %fd39;

$L__BB0_20:
	mul.f32 	%f66, %f117, %f119;
	div.rn.f32 	%f22, %f66, 0f41100000;
	mul.f32 	%f67, %f22, 0f437F0000;
	cvt.rzi.s32.f32 	%r88, %f67;
	shl.b64 	%rd24, %rd7, 2;
	add.s64 	%rd25, %rd2, %rd24;
	st.global.u32 	[%rd25], %r88;
	cvt.f64.f32 	%fd40, %f22;
	setp.geu.f64 	%p48, %fd40, 0d3F847AE147AE147B;
	@%p48 bra 	$L__BB0_28;

	setp.eq.s32 	%p49, %r8, 0;
	@%p49 bra 	$L__BB0_49;

	add.s32 	%r90, %r44, -2;
	and.b32  	%r128, %r8, 3;
	setp.lt.u32 	%p50, %r90, 3;
	mov.u32 	%r126, 0;
	@%p50 bra 	$L__BB0_25;

	sub.s32 	%r125, %r8, %r128;

$L__BB0_24:
	add.s32 	%r92, %r126, %r14;
	mul.wide.u32 	%rd26, %r92, 4;
	add.s64 	%rd27, %rd2, %rd26;
	mov.u32 	%r93, 0;
	st.global.u32 	[%rd27], %r93;
	add.s32 	%r94, %r92, 1;
	mul.wide.u32 	%rd28, %r94, 4;
	add.s64 	%rd29, %rd2, %rd28;
	st.global.u32 	[%rd29], %r93;
	add.s32 	%r95, %r92, 2;
	mul.wide.u32 	%rd30, %r95, 4;
	add.s64 	%rd31, %rd2, %rd30;
	st.global.u32 	[%rd31], %r93;
	add.s32 	%r96, %r92, 3;
	mul.wide.u32 	%rd32, %r96, 4;
	add.s64 	%rd33, %rd2, %rd32;
	st.global.u32 	[%rd33], %r93;
	add.s32 	%r126, %r126, 4;
	add.s32 	%r125, %r125, -4;
	setp.ne.s32 	%p51, %r125, 0;
	@%p51 bra 	$L__BB0_24;

$L__BB0_25:
	setp.eq.s32 	%p52, %r128, 0;
	@%p52 bra 	$L__BB0_28;

	add.s32 	%r127, %r126, %r14;

$L__BB0_27:
	.pragma "nounroll";
	mul.wide.u32 	%rd34, %r127, 4;
	add.s64 	%rd35, %rd2, %rd34;
	mov.u32 	%r97, 0;
	st.global.u32 	[%rd35], %r97;
	add.s32 	%r127, %r127, 1;
	add.s32 	%r128, %r128, -1;
	setp.ne.s32 	%p53, %r128, 0;
	@%p53 bra 	$L__BB0_27;

$L__BB0_28:
	setp.eq.s32 	%p54, %r8, 0;
	@%p54 bra 	$L__BB0_49;

	mul.f32 	%f23, %f117, 0f437F0000;
	mov.u32 	%r133, 0;

$L__BB0_30:
	mov.f32 	%f128, 0f00000000;
	@%p1 bra 	$L__BB0_32;

	ld.global.u32 	%r99, [%rd3];
	cvt.rn.f32.u32 	%f69, %r99;
	mul.f32 	%f70, %f117, %f69;
	div.rn.f32 	%f71, %f70, 0f437F0000;
	add.s32 	%r100, %r7, %r133;
	mul.wide.u32 	%rd36, %r100, 4;
	add.s64 	%rd37, %rd1, %rd36;
	ld.global.u32 	%r101, [%rd37];
	cvt.rn.f32.u32 	%f72, %r101;
	div.rn.f32 	%f73, %f72, 0f437F0000;
	fma.rn.f32 	%f128, %f73, %f71, 0f00000000;

$L__BB0_32:
	@%p2 bra 	$L__BB0_34;

	ld.global.u32 	%r102, [%rd4];
	cvt.rn.f32.u32 	%f74, %r102;
	mul.f32 	%f75, %f117, %f74;
	div.rn.f32 	%f76, %f75, 0f437F0000;
	add.s32 	%r103, %r9, %r133;
	mul.wide.u32 	%rd38, %r103, 4;
	add.s64 	%rd39, %rd1, %rd38;
	ld.global.u32 	%r104, [%rd39];
	cvt.rn.f32.u32 	%f77, %r104;
	div.rn.f32 	%f78, %f77, 0f437F0000;
	fma.rn.f32 	%f128, %f78, %f76, %f128;

$L__BB0_34:
	@%p3 bra 	$L__BB0_36;

	ld.global.u32 	%r105, [%rd5];
	cvt.rn.f32.u32 	%f79, %r105;
	mul.f32 	%f80, %f117, %f79;
	div.rn.f32 	%f81, %f80, 0f437F0000;
	add.s32 	%r106, %r12, %r133;
	mul.wide.u32 	%rd40, %r106, 4;
	add.s64 	%rd41, %rd1, %rd40;
	ld.global.u32 	%r107, [%rd41];
	cvt.rn.f32.u32 	%f82, %r107;
	div.rn.f32 	%f83, %f82, 0f437F0000;
	fma.rn.f32 	%f128, %f83, %f81, %f128;

$L__BB0_36:
	@%p4 bra 	$L__BB0_38;

	ld.global.u32 	%r108, [%rd6];
	cvt.rn.f32.u32 	%f84, %r108;
	mul.f32 	%f85, %f117, %f84;
	div.rn.f32 	%f86, %f85, 0f437F0000;
	add.s32 	%r109, %r13, %r133;
	mul.wide.u32 	%rd42, %r109, 4;
	add.s64 	%rd43, %rd1, %rd42;
	ld.global.u32 	%r110, [%rd43];
	cvt.rn.f32.u32 	%f87, %r110;
	div.rn.f32 	%f88, %f87, 0f437F0000;
	fma.rn.f32 	%f128, %f88, %f86, %f128;

$L__BB0_38:
	@%p5 bra 	$L__BB0_40;

	ld.global.u32 	%r111, [%rd8];
	cvt.rn.f32.u32 	%f89, %r111;
	mul.f32 	%f90, %f117, %f89;
	div.rn.f32 	%f91, %f90, 0f437F0000;
	add.s32 	%r112, %r14, %r133;
	mul.wide.u32 	%rd44, %r112, 4;
	add.s64 	%rd45, %rd1, %rd44;
	ld.global.u32 	%r113, [%rd45];
	cvt.rn.f32.u32 	%f92, %r113;
	div.rn.f32 	%f93, %f92, 0f437F0000;
	fma.rn.f32 	%f128, %f93, %f91, %f128;

$L__BB0_40:
	@%p6 bra 	$L__BB0_42;

	ld.global.u32 	%r114, [%rd9];
	cvt.rn.f32.u32 	%f94, %r114;
	mul.f32 	%f95, %f117, %f94;
	div.rn.f32 	%f96, %f95, 0f437F0000;
	mul.wide.u32 	%rd46, %r129, 4;
	add.s64 	%rd47, %rd1, %rd46;
	ld.global.u32 	%r115, [%rd47];
	cvt.rn.f32.u32 	%f97, %r115;
	div.rn.f32 	%f98, %f97, 0f437F0000;
	fma.rn.f32 	%f128, %f98, %f96, %f128;

$L__BB0_42:
	@%p7 bra 	$L__BB0_44;

	ld.global.u32 	%r116, [%rd10];
	cvt.rn.f32.u32 	%f99, %r116;
	mul.f32 	%f100, %f117, %f99;
	div.rn.f32 	%f101, %f100, 0f437F0000;
	mul.wide.u32 	%rd48, %r130, 4;
	add.s64 	%rd49, %rd1, %rd48;
	ld.global.u32 	%r117, [%rd49];
	cvt.rn.f32.u32 	%f102, %r117;
	div.rn.f32 	%f103, %f102, 0f437F0000;
	fma.rn.f32 	%f128, %f103, %f101, %f128;

$L__BB0_44:
	@%p8 bra 	$L__BB0_46;

	ld.global.u32 	%r118, [%rd11];
	cvt.rn.f32.u32 	%f104, %r118;
	mul.f32 	%f105, %f117, %f104;
	div.rn.f32 	%f106, %f105, 0f437F0000;
	mul.wide.u32 	%rd50, %r131, 4;
	add.s64 	%rd51, %rd1, %rd50;
	ld.global.u32 	%r119, [%rd51];
	cvt.rn.f32.u32 	%f107, %r119;
	div.rn.f32 	%f108, %f107, 0f437F0000;
	fma.rn.f32 	%f128, %f108, %f106, %f128;

$L__BB0_46:
	@%p9 bra 	$L__BB0_48;

	ld.global.u32 	%r120, [%rd12];
	cvt.rn.f32.u32 	%f109, %r120;
	mul.f32 	%f110, %f117, %f109;
	div.rn.f32 	%f111, %f110, 0f437F0000;
	mul.wide.u32 	%rd52, %r132, 4;
	add.s64 	%rd53, %rd1, %rd52;
	ld.global.u32 	%r121, [%rd53];
	cvt.rn.f32.u32 	%f112, %r121;
	div.rn.f32 	%f113, %f112, 0f437F0000;
	fma.rn.f32 	%f128, %f113, %f111, %f128;

$L__BB0_48:
	div.rn.f32 	%f114, %f128, 0f41100000;
	mul.f32 	%f115, %f23, %f114;
	div.rn.f32 	%f116, %f115, %f22;
	cvt.rzi.s32.f32 	%r122, %f116;
	add.s32 	%r123, %r14, %r133;
	mul.wide.u32 	%rd54, %r123, 4;
	add.s64 	%rd55, %rd2, %rd54;
	st.global.u32 	[%rd55], %r122;
	add.s32 	%r132, %r132, 1;
	add.s32 	%r131, %r131, 1;
	add.s32 	%r130, %r130, 1;
	add.s32 	%r129, %r129, 1;
	add.s32 	%r133, %r133, 1;
	setp.lt.u32 	%p55, %r133, %r8;
	@%p55 bra 	$L__BB0_30;

$L__BB0_49:
	ret;

}

